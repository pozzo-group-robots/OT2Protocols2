{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.path import Path\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import preprocessing\n",
    "from itertools import product\n",
    "from scipy import interpolate, stats\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from matplotlib import animation\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish google drive integration: organize it so no longer need to pull test cases and transfer them constantly\n",
    "# better saving name system once merged to distnguish ?\n",
    "# make a quick little code for navigating back from a directory when doing test cases\n",
    "# Sort code structure and do test cases\n",
    "# work on outline for paper\n",
    "# Push commits for sonication station\n",
    "# QD updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data as a dataframe, \n",
    "path1 = r\"C:\\Users\\Edwin\\Downloads\\test_df\"\n",
    "path2 = r\"C:\\Users\\Edwin\\Desktop\\12_2_2020\\12_2_20_info\"\n",
    "path3 = r\"C:\\Users\\Edwin\\Desktop\\11_17_2020\\11_17_20_merged_info\"\n",
    "path4 = r\"C:\\Users\\Edwin\\Desktop\\11_18_2020\\11_18_20_merged_info\"\n",
    "data = pd.read_csv(path1) \n",
    "data\n",
    "data = data[data['400.0nm'] < 0.2] # remove sample outlier, but in reality should not be needed to remove\n",
    "# data = data[::3] # to select at random, rdm num gen and then select from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont know ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load/isolate variable inputs and outputs\n",
    "comp1 = np.asarray(pd.to_numeric(data['Component 1 wtf'] , errors='coerce')[1:-1]) # -1 removes the blank\n",
    "comp2 = np.asarray(pd.to_numeric(data['Component 2 wtf'] , errors='coerce')[1:-1]) # -1 removes the blank\n",
    "comp3 = np.asarray(pd.to_numeric(data['Component 3 wtf'] , errors='coerce')[1:-1]) # -1 removes the blank\n",
    "comp4 = np.asarray(pd.to_numeric(data['Component 4 wtf'] , errors='coerce')[1:-1])\n",
    "comp5 = np.asarray(pd.to_numeric(data['Component 5 wtf'] , errors='coerce')[1:-1])\n",
    "\n",
    "absorbance_400 = np.asarray(pd.to_numeric(data['400.0nm'] , errors='coerce')[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and standardize data\n",
    "x1_training = comp4\n",
    "x2_training = comp3\n",
    "y_training = absorbance_400\n",
    "\n",
    "value = 25\n",
    "x1_training_f = x1_training[:, np.newaxis]\n",
    "scalerx1 = preprocessing.RobustScaler().fit(x1_training_f) #not a huge diff between robustscalar and standardscalar\n",
    "x1_training_scaled = scalerx1.transform(x1_training_f)\n",
    "\n",
    "x2_training_f = x2_training[:, np.newaxis]\n",
    "scalerx2 = preprocessing.RobustScaler().fit(x2_training_f)\n",
    "x2_training_scaled = scalerx2.transform(x2_training_f)\n",
    "\n",
    "x1x2_training_scaled = np.asarray([x1_training_scaled[:,0], x2_training_scaled[:,0]]).T\n",
    "\n",
    "y_training_f = y_training[:, np.newaxis]\n",
    "scalery = preprocessing.RobustScaler().fit(y_training_f)\n",
    "y_training_scaled = scalery.transform(y_training_f)\n",
    "# [:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1x2_training_scaled # the higher dimension requirment all stemmed from this : /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.05, kernel=1**2 * RBF(length_scale=1),\n",
       "                         n_restarts_optimizer=10, normalize_y=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model and fit the data \n",
    "kernal = C(1, (1e-1, 1e3)) * RBF(1, (1e-3, 1e3)) \n",
    "gpmodel = GaussianProcessRegressor(kernel=kernal, n_restarts_optimizer=10,alpha=0.05, normalize_y=True) # random_state=42\n",
    "gpmodel.fit(x1x2_training_scaled, y_training_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create test data and mesh\n",
    "\n",
    "# I dont think you need to scale the linspace just make it to min and max of the scaled data\n",
    "# Do the product mesh operation, then after you predict you can convert using the inverse since its in the min and max linspace of scaled\n",
    "# odd since you never applied it to the thing to being with by lets see\n",
    "\n",
    "\n",
    "# All data is in (1,n) format for easier working with sklearn, need to convert if need list or value \n",
    "# you can make it so you start with bare exposed \n",
    "# NOTE making the input of min a array of (1,1) creates a different dim linspace\n",
    "x1_sct_min = min(x1_training_scaled) + min(x1_training_scaled)*0.2\n",
    "x1_sct_max = max(x1_training_scaled) + max(x1_training_scaled)*0.2\n",
    "x2_sct_min = min(x2_training_scaled) + min(x2_training_scaled)*0.2\n",
    "x2_sct_max = max(x2_training_scaled) + max(x2_training_scaled)*0.2\n",
    "\n",
    "# test data is inherently scaled given the inputs, if not then would need to rescale\n",
    "x1_test= np.linspace(x1_sct_min,x1_sct_max,100)\n",
    "x2_test = np.linspace(x2_sct_min,x2_sct_max,100)\n",
    "\n",
    "dim_x1_test = x1_test.shape[0] \n",
    "dim_x2_test = x2_test.shape[0]\n",
    "\n",
    "x1x2_test = np.array(list(product(x1_test, x2_test)))\n",
    "x1_test_expanded = x1x2_test[:,0][:,0]\n",
    "x2_test_expanded = x1x2_test[:,1][:,0]\n",
    "\n",
    "# verifying test arrays and resulting mesh are in range of test data\n",
    "plt.scatter(x1_test, x2_test)\n",
    "plt.scatter(x1_training_scaled, x2_training_scaled)\n",
    "plt.scatter(x1x2_test[:,0][:,0], x1x2_test[:,1][:,0], alpha = 0.03)\n",
    "\n",
    "# build the hull from scipy.spatial import ConvexHull\n",
    "hull_1 = x1_training_scaled[:,0]\n",
    "hull_2 = x2_training_scaled[:,0]\n",
    "hull_2d_points = np.asarray([hull_1, hull_2]).T\n",
    "hull = ConvexHull(hull_2d_points)\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(hull_2d_points[simplex, 0], hull_2d_points[simplex, 1], 'k-')\n",
    "    \n",
    "# to check if point within hull \n",
    "hull_path = Path(hull_2d_points[hull.vertices])\n",
    "# test_point = [0.6, 0.001]\n",
    "# plt.plot(test_point[0],test_point[1],'o')\n",
    "\n",
    "x1_inhull = []\n",
    "x2_inhull = []\n",
    "for x1, x2 in zip(x1_test_expanded, x2_test_expanded):\n",
    "    if hull_path.contains_point((x1,x2)) == True:\n",
    "        x1_inhull.append(x1)\n",
    "        x2_inhull.append(x2)\n",
    "        plt.plot(x1,x2,'o',c='r')\n",
    "x1_inhull = np.asarray(x1_inhull)  \n",
    "x2_inhull = np.asarray(x2_inhull)  \n",
    "\n",
    "dim_x1_hull = x1_inhull.shape[0] \n",
    "dim_x2_hull = x1_inhull.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2092063ca90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1x2_test_reform = np.asarray([x1_test_expanded, x2_test_expanded]).T\n",
    "y_pred, MSE = gpmodel.predict(x1x2_test_reform, return_std=True) \n",
    "\n",
    "# You should be able to look at x1_test_inv and x2_test_inx and be able to see the same mesh but just with scaled acise\n",
    "x1_test_inv = scalerx1.inverse_transform(x1x2_test[:,0]) # get to points of scatter, also no need for extra [:,0] as needed in 2D formate for inverse\n",
    "x2_test_inv = scalerx2.inverse_transform(x1x2_test[:,1])\n",
    "y_pred_inv = scalery.inverse_transform(y_pred)\n",
    "plt.scatter(x1_test_inv, x2_test_inv, c = y_pred_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_test_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2091fff4780>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1x2_test_reform = np.asarray([x1_inhull, x2_inhull]).T\n",
    "y_pred, MSE = gpmodel.predict(x1x2_test_reform, return_std=True) \n",
    "x1_test_inv = scalerx1.inverse_transform(x1_inhull[:, np.newaxis])\n",
    "x2_test_inv = scalerx2.inverse_transform(x2_inhull[:, np.newaxis])\n",
    "y_pred_inv = scalery.inverse_transform(y_pred)\n",
    "plt.scatter(x1_test_inv, x2_test_inv, c = y_pred_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4069, 1) (4069, 1) (4069, 1)\n",
      "(63, 63) (63, 63) (63, 63) (3969, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now here is where you need to decide whether to look at original or scaled data\n",
    "x1 = x1_training\n",
    "x2 = x2_training\n",
    "y = y_training\n",
    "\n",
    "# Not necessary to be 1D or not, jsut need to have enoguh elements in correct oreitnation to reorder\n",
    "# so here is where you would restrict the hull\n",
    "x1_mesh_prep = x1_test_inv\n",
    "x2_mesh_prep = x2_test_inv\n",
    "y_mesh_prep = y_pred_inv\n",
    "\n",
    "\n",
    "# trying to remove one to make even\n",
    "dim = math.sqrt(x1_mesh_prep.shape[0])\n",
    "dim_rounded = int(round(dim,0)-1)\n",
    "dim_squared = int(dim_rounded*dim_rounded)\n",
    "print(x1_mesh_prep.shape, x2_mesh_prep.shape, y_mesh_prep.shape)\n",
    "\n",
    "x1_mesh_prep = x1_test_inv[0:dim_squared]\n",
    "x2_mesh_prep = x2_test_inv[0:dim_squared]\n",
    "y_mesh_prep = y_pred_inv[0:dim_squared]\n",
    "\n",
    "new_dim = dim_rounded\n",
    "dim_x1_test = new_dim\n",
    "dim_x2_test = new_dim\n",
    "\n",
    "\n",
    "X1 = x1_mesh_prep.reshape(dim_x2_test, dim_x1_test)\n",
    "X2 = x2_mesh_prep.reshape(dim_x2_test, dim_x1_test)\n",
    "Y = np.reshape(y_mesh_prep,(dim_x2_test, dim_x1_test))\n",
    "print(X1.shape, X2.shape, Y.shape, y_mesh_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_pad_nan(array):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 1.000e+00, 2.000e+00, ..., 6.100e+01, 6.200e+01,\n",
       "        6.300e+01],\n",
       "       [6.400e+01, 6.500e+01, 6.600e+01, ..., 1.250e+02, 1.260e+02,\n",
       "        1.270e+02],\n",
       "       [1.280e+02, 1.290e+02, 1.300e+02, ..., 1.890e+02, 1.900e+02,\n",
       "        1.910e+02],\n",
       "       ...,\n",
       "       [3.904e+03, 3.905e+03, 3.906e+03, ..., 3.965e+03, 3.966e+03,\n",
       "        3.967e+03],\n",
       "       [3.968e+03, 3.969e+03, 3.970e+03, ..., 4.029e+03, 4.030e+03,\n",
       "        4.031e+03],\n",
       "       [4.032e+03, 4.033e+03, 4.034e+03, ...,       nan,       nan,\n",
       "              nan]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4069\n",
    "a = np.arange(n)\n",
    "ns = np.ceil(np.sqrt(n)).astype(int)\n",
    "s = np.zeros(ns**2)\n",
    "s[:] = np.nan\n",
    "print(s)\n",
    "s[:a.size] = a\n",
    "s = s.reshape(ns,ns)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4069, 4069) (4069, 4069) (4069,)\n"
     ]
    }
   ],
   "source": [
    "X1,X2= np.meshgrid(x1_mesh_prep,x2_mesh_prep)\n",
    "Y = y_mesh_prep[:,0]\n",
    "print(X1.shape, X2.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think just add one (for extrapolation) then divide to get the even dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# issue since now cannot reshape as dimension of origional was lost, unless somehow can go reverse inverse of product...\n",
    "# maybe mesh grid, just remember that e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) (100, 100) (100, 100) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X1 = x1_mesh_prep.reshape(dim_x2_test, dim_x1_test)\n",
    "X2 = x2_mesh_prep.reshape(dim_x2_test, dim_x1_test)\n",
    "Y = np.reshape(y_mesh_prep,(dim_x2_test, dim_x1_test))\n",
    "print(X1.shape, X2.shape, Y.shape, y_mesh_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'PFH wtf')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "# where should the vmin and vmax, it should be on training data\n",
    "vmin = min(y) # anything fed into mpl will expose it to the final\n",
    "vmax = max(y)\n",
    "norm =colors.Normalize(vmin=vmin,vmax=vmax) # is this normalization correct?\n",
    "\n",
    "mappable = ax.pcolormesh(X1,X2,Y, norm=norm, shading = 'auto')\n",
    "cbar = fig.colorbar(mappable)\n",
    "cbar.ax.set_ylabel('AU at 400nm')\n",
    "ax.scatter(x1,x2,c=y, norm=norm, edgecolors='k')\n",
    "ax.set_xlabel('Ethanol wtf')\n",
    "ax.set_ylabel('PFH wtf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'AU at 400nm')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot with MSE\n",
    "# populate outline with expl. of what you are doing here: What is robust scalar, fundamentals of model and limitations. \n",
    "# Contour plot, with convex hull\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x1,x2,y, c=y, norm=norm, cmap='jet')\n",
    "ax.plot_surface(X=X1, Y=X2, Z=Y, norm=norm, rstride=1, alpha =0.1, cstride=1, cmap='jet', linewidth=0, antialiased=False)\n",
    "\n",
    "cbaxes = fig.add_axes([0.7, 0.85, 0.2, 0.03]) \n",
    "cb = fig.colorbar(cm.ScalarMappable(norm=norm,cmap='jet'), shrink=0.3, aspect=5, cax = cbaxes, orientation='horizontal')\n",
    "cb.ax.set_title('AU at 400nm', rotation=0)\n",
    "\n",
    "ax.set_xlabel('Ethanol (wtf)')\n",
    "ax.set_ylabel('Perfluorocarbon (wtf)')\n",
    "ax.set_zlabel('AU at 400nm')\n",
    "# ax.set_zlim(0.0,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "cbaxes = fig.add_axes([0.7, 0.85, 0.2, 0.03]) \n",
    "\n",
    "\n",
    "def init():\n",
    "    # Plot the surface.\n",
    "    ax.scatter(x1,x2,y, c=y, norm=norm, cmap='jet')\n",
    "    ax.plot_surface(X=X1, Y=X2, Z=Y, norm=norm, rstride=1, alpha =0.1, cstride=1, cmap='jet', linewidth=0, antialiased=False)\n",
    "    cb = fig.colorbar(cm.ScalarMappable(norm=norm,cmap='jet'), shrink=0.3, aspect=5, cax = cbaxes, orientation='horizontal')\n",
    "    cb.ax.set_title('AU at 400nm', rotation=0)\n",
    "    ax.set_xlabel('Ethanol (wtf)')\n",
    "    ax.set_ylabel('Perfluorocarbon (wtf)')\n",
    "    ax.set_zlabel('AU at 400nm')\n",
    "    ax.set_zlim(0.0,0.1)\n",
    "    return fig,\n",
    "\n",
    "def animate(i):\n",
    "    # azimuth angle : 0 deg to 360 deg\n",
    "    ax.view_init(elev=10, azim=i)\n",
    "    return fig,\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=90, interval=50, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'GP_rotating'\n",
    "ani.save(fn+'.gif',writer='imagemagick',fps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X**2 + Y**2)\n",
    "Z = np.sin(R)\n",
    "\n",
    "# Create a figure and a 3D Axes\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "def init():\n",
    "    # Plot the surface.\n",
    "    ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "    return fig,\n",
    "\n",
    "def animate(i):\n",
    "    # azimuth angle : 0 deg to 360 deg\n",
    "    ax.view_init(elev=10, azim=i)\n",
    "    return fig,\n",
    "\n",
    "# Animate\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=90, interval=50, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'rotate_azimuth_angle_3d_surf_slow'\n",
    "ani.save(fn+'.gif',writer='imagemagick',fps=1000/50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cmd = 'magick convert %s.gif -fuzz 5%% -layers Optimize %s_r.gif'%(fn,fn)\n",
    "# subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['animation.html'] = 'html5'\n",
    "ani"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
